{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d455d0e7",
   "metadata": {},
   "source": [
    "## Task - Twitter Topic Classification\n",
    "### Subtopics : Natural Language Processing, Supervised Machine Learning, Classification ,Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7a09ba",
   "metadata": {},
   "source": [
    "#### Goal is to build a Machine Learning Model that categories tweet cover to a variety of topics, namely:\n",
    "0. Arts & Culture\n",
    "1. Business & Entrepreneurs\n",
    "2. Pop Culture\n",
    "3. Daily Life\n",
    "4. Sports & Gaming\n",
    "5. Science & Technology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f110c7",
   "metadata": {},
   "source": [
    "##### To fulfill this goal, we'll follow the CRISP-DM methodology, which stands for Cross-Industry Standard Process for Data Mining. Here's how we'll proceed:\n",
    "\n",
    "1. Business Understanding: Understand the task and objectives, which involve classifying tweets into predefined categories.\n",
    "\n",
    "2. Data Understanding: Examine the dataset provided, understand its structure, and explore some basic statistics.\n",
    "\n",
    "3. Data Preparation: Preprocess the text data, handle missing values, tokenize the text, remove stopwords, and perform any other necessary transformations. Additionally, split the dataset into training and testing sets.\n",
    "\n",
    "4. Modeling: Select suitable classification models (e.g., Naive Bayes, Logistic Regression, etc.) and train them using the training data.\n",
    "\n",
    "5. Evaluation: Evaluate the trained models using appropriate evaluation metrics such as accuracy, precision, recall, and F1-score. Compare the performance of different models and pipeline choices.\n",
    "\n",
    "6. Deployment: Deploy the best-performing model for practical use, if applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe09c481",
   "metadata": {},
   "source": [
    "### 1.  Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd805ab3",
   "metadata": {},
   "source": [
    "Goal is to produce a pipeline capable of solving a multi-class classification task in the\n",
    "form of a research project - whereby comparisons are made and assessed towards the task.\n",
    "For this you will follow the CRISP-DM Methodology (see Figure 2) covered in the module,\n",
    "evidencing your process in your report. Multiple approaches will be compared, and final\n",
    "evaluations and recommendations made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cb348e",
   "metadata": {},
   "source": [
    "### 2. Data Understanding\n",
    "We have a JSON file containing 6443 entries which represent\n",
    "tweets from the social media platform Twitter, covering 6 topics. These tweets were gathered\n",
    "between 2019 and 2021 and were human-labelled using Amazon’s Mechanical Turk.\n",
    "The categories of tweet cover a variety of topics, namely:\n",
    "\n",
    "0. Arts & Culture\n",
    "1. Business & Entrepreneurs\n",
    "2. Pop Culture\n",
    "3. Daily Life\n",
    "4. Sports & Gaming\n",
    "5. Science & Technology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdf21e4",
   "metadata": {},
   "source": [
    "### 3. Data Preparation\n",
    "This include steps such as :Preprocessing the text data, handling missing values, tokenizing the text, removing stopwords, and performing any other necessary transformations. Additionally, splitting of the dataset into training and testing sets before modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04508474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all needed libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e930569e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text       date  label  \\\n",
      "0  The {@Clinton LumberKings@} beat the {@Cedar R... 2019-09-08      4   \n",
      "1  I would rather hear Eli Gold announce this Aub... 2019-09-08      4   \n",
      "2  Someone take my phone away, I’m trying to not ... 2019-09-08      4   \n",
      "\n",
      "                    id       label_name  \n",
      "0  1170516324419866624  sports_&_gaming  \n",
      "1  1170516440690176006  sports_&_gaming  \n",
      "2  1170516543387709440  sports_&_gaming  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6443 entries, 0 to 6442\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   text        6443 non-null   object        \n",
      " 1   date        6443 non-null   datetime64[ns]\n",
      " 2   label       6443 non-null   int64         \n",
      " 3   id          6443 non-null   int64         \n",
      " 4   label_name  6443 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(2)\n",
      "memory usage: 251.8+ KB\n",
      "None\n",
      "             label            id\n",
      "count  6443.000000  6.443000e+03\n",
      "mean      2.910756  1.298320e+18\n",
      "std       1.148659  7.871683e+16\n",
      "min       0.000000  1.170516e+18\n",
      "25%       2.000000  1.226439e+18\n",
      "50%       3.000000  1.300101e+18\n",
      "75%       4.000000  1.368440e+18\n",
      "max       5.000000  1.432129e+18\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the dataset\n",
    "df = pd.read_json(\"CETM47-23_24-AS2-Data.json\")\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head(3))\n",
    "\n",
    "# Display basic information about the dataframe\n",
    "print(df.info())\n",
    "\n",
    "# Display summary statistics of the numerical columns\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9b494d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts:\n",
      "2    2512\n",
      "4    2291\n",
      "3     883\n",
      "5     326\n",
      "1     287\n",
      "0     144\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for imbalance datasets\n",
    "class_counts = df['label'].value_counts()\n",
    "print(\"Class Counts:\")\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d574f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Upsample minority classes if necessary\n",
    "# def upsample_minority(df):\n",
    "#     majority_class = df['label'].value_counts().idxmax()\n",
    "#     minority_classes = df['label'].value_counts().drop(index=majority_class)\n",
    "#     minority_upsampled = [resample(df[df['label'] == cls], replace=True, n_samples=class_counts.max(), random_state=42) for cls in minority_classes.index]\n",
    "#     return pd.concat([df[df['label'] == majority_class]] + minority_upsampled)\n",
    "\n",
    "# df_balanced = upsample_minority(df)\n",
    "df_balanced = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dacc5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Accuracy: 0.40496508921644686\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        25\n",
      "           1       0.00      0.00      0.00        60\n",
      "           2       0.42      0.76      0.54       497\n",
      "           3       0.06      0.01      0.01       179\n",
      "           4       0.41      0.31      0.35       468\n",
      "           5       0.12      0.02      0.03        60\n",
      "\n",
      "    accuracy                           0.40      1289\n",
      "   macro avg       0.17      0.18      0.15      1289\n",
      "weighted avg       0.32      0.40      0.34      1289\n",
      "\n",
      "\n",
      "Naive Bayes Accuracy: 0.30411171450737007\n",
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.16      0.04        25\n",
      "           1       0.07      0.13      0.09        60\n",
      "           2       0.45      0.58      0.51       497\n",
      "           3       0.15      0.09      0.12       179\n",
      "           4       0.47      0.15      0.22       468\n",
      "           5       0.05      0.08      0.06        60\n",
      "\n",
      "    accuracy                           0.30      1289\n",
      "   macro avg       0.20      0.20      0.17      1289\n",
      "weighted avg       0.37      0.30      0.30      1289\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/apple/anaconda3/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 - 281s - 3s/step - accuracy: 0.3894 - loss: 1.4778 - val_accuracy: 0.4500 - val_loss: 1.3513\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_balanced['text'])\n",
    "X = tokenizer.texts_to_sequences(df_balanced['text'])\n",
    "X = pad_sequences(X)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y = to_categorical(df_balanced['label'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train.argmax(axis=1))\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test.argmax(axis=1), y_pred_lr)\n",
    "print(\"\\nLogistic Regression Accuracy:\", accuracy_lr)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test.argmax(axis=1), y_pred_lr))\n",
    "\n",
    "# Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train.argmax(axis=1))\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "accuracy_nb = accuracy_score(y_test.argmax(axis=1), y_pred_nb)\n",
    "print(\"\\nNaive Bayes Accuracy:\", accuracy_nb)\n",
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_test.argmax(axis=1), y_pred_nb))\n",
    "\n",
    "# Deep Learning Model\n",
    "embedding_dim = 100\n",
    "max_length = X.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=embedding_dim, input_length=max_length))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(len(class_counts), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"\\nDeep Learning Model Accuracy:\", scores[1])\n",
    "\n",
    "# Plot model accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f7a872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4815010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
